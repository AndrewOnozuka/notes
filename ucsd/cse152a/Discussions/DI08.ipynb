{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Escb-oGmLC"
      },
      "source": [
        "# CSE 152A: Discussion Week 8: PyTorch Tutorials\n",
        "Adapted from: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXeQqEAYICmh"
      },
      "source": [
        "## **Part 0: Set-up**\n",
        "### First, lets import PyTorch and some useful functions/objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsUlJRrTGqmf"
      },
      "outputs": [],
      "source": [
        "import torch # Main torch package\n",
        "from torch import nn # Importing specifically the nn class of the torch library, this will make our code more consise later on\n",
        "from torch.utils.data import DataLoader # Importing the DataLoader class\n",
        "from torchvision import datasets # Used for importing built-in datasets\n",
        "from torchvision.transforms import ToTensor # Used to transform data to tensors (the main object in PyTorch)\n",
        "import matplotlib.pyplot as plt # Plotting\n",
        "import numpy as np\n",
        "from tqdm import tqdm # Progress bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOj2RXu1HV4Q"
      },
      "source": [
        "###  Let's specify a variable to use GPU if available and CPU if not. CUDA is the API for working with NVIDIA GPUs. There is good support in Pytorch to work with CUDA and NVIDIA GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZtqLXRqG8K3",
        "outputId": "381f91dc-4bbe-4cc0-8056-103efd3031f3"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "print(f\"The device currently available is: {device}\")\n",
        "!nvidia-smi # This will show information about your GPU if there is one available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tWZUZR7H7bf"
      },
      "source": [
        "### If you have \"cpu\", then it means that there is no GPU currently available that CUDA can find. This is because in Google Colab, we need to activate it.\n",
        "\n",
        "**NOTE: There is a time limit for GPU usage per day. If you reach this time limit while doing the HW, we do NOT expect you to purchase a subscription to Colab Pro. Please just save your notebook and copy it over to another Gmail account and work on it there while your school Google account is on cooldown.**\n",
        "\n",
        "### To activate it, we can click at the top: Runtime -> Change Runtime Type -> Select T4 GPU under the Hardware Accelerator selection. You will probably need to run your cells again.\n",
        "\n",
        "### At this point, you should hopefully see that the device currently available is cuda!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkDr0h_5QUef"
      },
      "source": [
        "### **Tensors**\n",
        "\n",
        "The main object in PyTorch are tensors, similar to Numpy ndarrays. Main difference is PyTorch has built-in GPU/hardware acceleration support. You can also easily switch between PyTorch tensors and Numpy ndarrays.\n",
        "\n",
        "[Bridging Numpy and PyTorch](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fyw45FqQMym",
        "outputId": "eefae922-5ab3-406d-c684-0453659c4694"
      },
      "outputs": [],
      "source": [
        "# Initializing a tensor\n",
        "data = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "])\n",
        "print(data)\n",
        "print(data.shape)\n",
        "print()\n",
        "\n",
        "# Starting with a numpy array\n",
        "np_arr = np.array([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "])\n",
        "data = torch.tensor(np_arr)\n",
        "print(data)\n",
        "print(data.shape)\n",
        "print()\n",
        "\n",
        "# And switch back\n",
        "np_arr = data.numpy()\n",
        "print(np_arr)\n",
        "print(np_arr.shape)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEdr_vmYLHqX"
      },
      "source": [
        "## **Part 1: Initializing your dataset**\n",
        "### Your dataset will determine some of how your network needs to be set-up. There are two main objects you need to set-up: the Dataset and DataLoader. Pytorch has a few datasets built into it, so we will use the CIFAR-10 dataset for this tutorial. You can read more in the tutorials about how to initialize your own Dataset and Dataloaders for custom data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "kMShCJEWL8s7",
        "outputId": "75256389-3823-4a7c-abed-f0096ccaf770"
      },
      "outputs": [],
      "source": [
        "# Download datasets\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "testing_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=batch_size)\n",
        "\n",
        "for X,y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "\n",
        "    plt.imshow(X[1,:,:,:].permute(1,2,0)) # Show an image from our dataset\n",
        "    print(f\"This image is of class {y[1]}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlYFVUQlJOAB"
      },
      "source": [
        "### At this point, we have downloaded our data and set-up our data loaders. You can see that we can do .shape on these tensor objects just like Numpy, however note the dimensions are probably not in the order you are expecting. Here, we have shape (batch_size, channels, height, width). Channels is the third dimension of your images (think RGB). Height and width are specified last in the dimensions. Many PyTorch functions *expect* the input to be this way.\n",
        "\n",
        "## **Part 2: Defining your network**\n",
        "\n",
        "### Each network/layer in PyTorch should be defined inside of a class that inherits from nn.Module. There are then two things we need to do: Initialize the layers inside of the constructor, and specify how data should pass through the network in the forward function.\n",
        "\n",
        "### I have intentionally created a small and simple network to get the PyTorch concepts across and will obtain somewhat poor accuracy. In HW4, we will improve upon this.\n",
        "\n",
        "[Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "\n",
        "[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "\n",
        "[ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "\n",
        "[Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQqFe9UKJUxe",
        "outputId": "e7245273-d700-4da7-ebf7-90cc2d471935"
      },
      "outputs": [],
      "source": [
        "class MyNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    This is the constructor of our neural network. Inside of it, we should\n",
        "    specify all of the layers that are used to build the model.\n",
        "\n",
        "    Lets say that we want to create a network with 2 convolutional layers\n",
        "    and 3 fully-connected layers. For now:\n",
        "\n",
        "    1. Conv2d: 8 output channels, kernel of size 3, no padding, no stride (takes the image data as input)\n",
        "    2. Conv2d: 16 output channels, kernel of size, no padding, no stride\n",
        "    3. Linear: 1028 output features\n",
        "    2. Linear: 128 output features\n",
        "    3. Linear: 10 output features (This is produces our output)\n",
        "\n",
        "    With ReLU activation function after each convolutional and linear layer.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.conv1 = # Convolutional layer 1: in_channels depends on input data\n",
        "    self.conv2 = # Convolutional layer 2: in_channels depends on output from conv1\n",
        "    self.fc1 = # Fully connected layer 1: Must flatten tensor from conv1 before passing to fc1 (in_features)\n",
        "    self.fc2 = # Fully connected layer 2: in_features only depends on fc1\n",
        "    self.fc3 = # Fully connected layer 3: in_features only depends on fc2\n",
        "\n",
        "    self.relu = # ReLU activation function (can be used multiple times since no parameters)\n",
        "    self.flatten = # Used for flattening the tensor for fc layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Here, we should specify how our model takes in our input data x\n",
        "    and feeds it through the network. In this case, x will\n",
        "    be the images obtained from the data loader (tensors).\n",
        "    \"\"\"\n",
        "\n",
        "    return # Note: We do not need to apply an activation function to the output of the network\n",
        "\n",
        "\n",
        "# Now we can instantiate a network:\n",
        "model = MyNetwork() # Create/Initialze the model\n",
        "model.to(device) # Send the model to the device we've chosen (either GPU or CPU depending on what's available)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE2VdjqkD94g"
      },
      "source": [
        "## **Part 3: Training and Evaluating**\n",
        "\n",
        "After we've set-up our network, they currently have randomly initialized weights. We need to optimize the network for our problem (classification). So, we need to decide on our loss function, the optimizer we will use, and then just feed our data through.\n",
        "\n",
        "[Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)\n",
        "\n",
        "[CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S4vL_8_EFXn"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss() # Initialize our loss function\n",
        "optimizer = torch.optim.Adam(model.parameters()) # Initialize our optimizer -- we pass in the parameters that we want to optimize\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "  \"\"\"\n",
        "  This function will perform the optimization/training of the network\n",
        "  \"\"\"\n",
        "  size = len(dataloader.dataset) # Grab the total number of images\n",
        "  model.train() # Set the model to training mode (parameters can be updated and gradients are calculated)\n",
        "  loss_history = []\n",
        "\n",
        "  # Now, we loop over our training data, pass in a batch, calculate the loss,\n",
        "  # calculate gradients, and update the our weights through the optimizer\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Zero out the gradients\n",
        "\n",
        "    # First, we need to move the data to the same device as the model\n",
        "    # Ideally, everything is done on GPU\n",
        "\n",
        "    # Then, we can just pass the data through the model (forward)\n",
        "\n",
        "    # and calculate the loss\n",
        "\n",
        "    # Now, we can calculate the gradients through backpropagation\n",
        "\n",
        "    # Take a step along the direction of the gradient (minimize)\n",
        "\n",
        "    # Logging\n",
        "    loss, current = loss.item(), (batch+1)*len(X)\n",
        "    if batch % 100 == 0:\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    loss_history.append(loss)\n",
        "\n",
        "  return loss_history\n",
        "\n",
        "def test(dataloader, model, loss_fn, device):\n",
        "  \"\"\"\n",
        "  This function will test/evaluate our network after training\n",
        "  \"\"\"\n",
        "  size = len(dataloader.dataset) # Grab the total number of images\n",
        "  num_batches = len(dataloader) # Grab the total number of batches\n",
        "  model.eval() # Set the network to eval mode\n",
        "  test_loss, correct = 0.0, 0.0\n",
        "  with torch.no_grad(): # Ensure we do not calculate gradients\n",
        "    for X, y in dataloader:\n",
        "\n",
        "      # Send data to same device as model\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # Pass the data through the model\n",
        "      pred = model(X)\n",
        "\n",
        "      # Compute the loss on the test set\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "\n",
        "      # Compute the number of correct predictions\n",
        "      correct += (pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  # Get the average test loss\n",
        "  test_loss /= num_batches\n",
        "\n",
        "  # Compute the accuracy\n",
        "  acc = correct / size\n",
        "\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJW4ti09GqFV",
        "outputId": "0660d2e2-7638-4061-80b9-3d91c2494886"
      },
      "outputs": [],
      "source": [
        "# Now, we can just call the functions we've written\n",
        "\n",
        "# Training\n",
        "epochs = 3\n",
        "train_loss = []\n",
        "for t in range(epochs):\n",
        "  train_loss += train(train_dataloader, model, loss_fn, optimizer, device)\n",
        "\n",
        "  # Testing\n",
        "  print(f\"\\nEpoch {t}:\")\n",
        "  test(test_dataloader, model, loss_fn, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "wB5crjvmMPHs",
        "outputId": "6ef9184b-c042-4359-c3a7-9760d13df5e4"
      },
      "outputs": [],
      "source": [
        "# Now, we can plot our training loss\n",
        "plt.plot(range(len(train_loss)), train_loss)\n",
        "plt.xlabel(\"Batch Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNMMlcJaSk6p"
      },
      "source": [
        "## We have now completed a quick-start tutorial on creating a CNN and training it! Let's briefly talk about gradient calculation in PyTorch.\n",
        "\n",
        "## **Autograd**\n",
        "###Now we can briefly discuss automatic differentiation and gradients. Remember the loss_fn.backward()? This calculated the gradients of each parameter in our network using *backpropagation* (we will discuss this in lecture). PyTorch has automatic differentiation built-in to it.\n",
        "[Automatic differentiation with autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP0BdlUzSyGc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
