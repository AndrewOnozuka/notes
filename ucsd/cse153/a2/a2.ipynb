{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 – Task 1 Symbolic, Unconditioned Generation\n",
    "\n",
    "This notebook implements and significantly extends the symbolic Markov model from Homework 3. We extract musical features (pitch and duration) from a dataset of MIDI files using the MiDiTok library and build unigram, bigram, and trigram models to learn a distribution p(x) over musical sequences. We evaluate models using perplexity and probability distributions, and sample new music using our trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from midiutil import MIDIFile\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from statistics import mean\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer and Dataset Setup\n",
    "\n",
    "We use the REMI tokenizer from MiDiTok to convert symbolic MIDI data into token sequences for modeling. This approach allows us to extract structured pitch, duration, and positional events from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load MIDI files and initialize tokenizer\n",
    "midi_files = glob(\"PDMX_subset/*.mid\")\n",
    "\n",
    "tokenizer = REMI(TokenizerConfig(\n",
    "    num_velocities=1,\n",
    "    use_chords=False,\n",
    "    use_programs=False\n",
    "))\n",
    "\n",
    "tokenizer.train(vocab_size=1000, files_paths=midi_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Markov Models (Pitch Only)\n",
    "\n",
    "We begin by re-implementing and extending the pitch-based unigram, bigram, and trigram models from Homework 3. These models serve as the baseline for measuring improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Extracts all pitch events (as integers) from a single MIDI file.\n",
    "\n",
    "def note_extraction(midi_file):\n",
    "    note_events = []\n",
    "    midi = Score(midi_file)\n",
    "    tokens = tokenizer(midi)[0].tokens\n",
    "    for token in tokens:\n",
    "        if 'Pitch' in token:\n",
    "            note = int(token.split('_')[1])\n",
    "            note_events.append(note)\n",
    "    return note_events\n",
    "\n",
    "#   Aggregates pitch counts over all MIDI files and returns a dictionary \n",
    "#   mapping each pitch to its total count.\n",
    "\n",
    "def note_frequency(midi_files):\n",
    "    note_counts = defaultdict(int)\n",
    "    for midi_file in midi_files:\n",
    "        note_events = note_extraction(midi_file)\n",
    "        for note in note_events:\n",
    "            note_counts[note] += 1\n",
    "    return note_counts\n",
    "\n",
    "#   Takes pitch counts from all MIDI files and normalizes them to produce\n",
    "#   a probability distribution over note pitch events.\n",
    "#   Returns a dictionary mapping each pitch to its probability.\n",
    "\n",
    "def note_unigram_probability(midi_files):\n",
    "    note_counts = note_frequency(midi_files)\n",
    "    \n",
    "    unigramProbabilities = {}\n",
    "    counts = sum(list(note_counts.values()))\n",
    "    for n in note_counts:\n",
    "        unigramProbabilities[n] = note_counts[n] / counts\n",
    "    return unigramProbabilities\n",
    "\n",
    "#   Computes bigram (pairwise) transition probabilities for notes.\n",
    "#   Returns:\n",
    "#       - bigramTransitions: {prev_note: [next_note1, next_note2, ...]}\n",
    "#       - bigramTransitionProbabilities: {prev_note: [p1, p2, ...]}\n",
    "\n",
    "def note_bigram_probability(midi_files):\n",
    "    bigrams = defaultdict(int)\n",
    "    \n",
    "    for file in midi_files:\n",
    "        note_events = note_extraction(file)\n",
    "        for (note1, note2) in zip(note_events[:-1], note_events[1:]):\n",
    "            bigrams[(note1, note2)] += 1\n",
    "            \n",
    "    bigramTransitions = defaultdict(list)\n",
    "    bigramTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    for b1,b2 in bigrams:\n",
    "        bigramTransitions[b1].append(b2)\n",
    "        bigramTransitionProbabilities[b1].append(bigrams[(b1,b2)])\n",
    "        \n",
    "    for k in bigramTransitionProbabilities:\n",
    "        Z = sum(bigramTransitionProbabilities[k])\n",
    "        bigramTransitionProbabilities[k] = [x / Z for x in bigramTransitionProbabilities[k]]\n",
    "        \n",
    "    return bigramTransitions, bigramTransitionProbabilities\n",
    "\n",
    "#   Samples the next note based on bigram transition probabilities,\n",
    "#   given the current note.\n",
    "\n",
    "def sample_next_note(note):\n",
    "    bigramTransitions, bigramTransitionProbabilities = note_bigram_probability(midi_files)\n",
    "    next_note = choice(bigramTransitions[note], 1, p=bigramTransitionProbabilities[note])[0]\n",
    "    return next_note\n",
    "\n",
    "#   Computes the perplexity of the bigram model on a given MIDI file.\n",
    "#   Uses:\n",
    "#       - p(w1) from unigram probability\n",
    "#       - p(w_i | w_{i-1}) from bigram transition probabilities\n",
    "#   Returns the perplexity value as a float.\n",
    "\n",
    "def note_bigram_perplexity(midi_file):\n",
    "    unigramProbabilities = note_unigram_probability(midi_files)\n",
    "    bigramTransitions, bigramTransitionProbabilities = note_bigram_probability(midi_files)\n",
    "    \n",
    "    note_events = note_extraction(midi_file)\n",
    "    perplexities = [unigramProbabilities[note_events[0]]]\n",
    "    for (note1, note2) in zip(note_events[:-1], note_events[1:]):\n",
    "        index = bigramTransitions[note1].index(note2)\n",
    "        prob = bigramTransitionProbabilities[note1][index]\n",
    "        perplexities.append(prob)\n",
    "\n",
    "    assert len(perplexities) == len(note_events)\n",
    "    perplexity = np.exp(-np.sum(np.log(perplexities)) / len(note_events))\n",
    "    return perplexity\n",
    "\n",
    "#   Computes trigram (second-order Markov) transition probabilities for notes.\n",
    "#   Returns:\n",
    "#       - trigramTransitions: {(note_{i-2}, note_{i-1}): [note_i, ...]}\n",
    "#       - trigramTransitionProbabilities: {(note_{i-2}, note_{i-1}): [p1, p2, ...]}\n",
    "\n",
    "\n",
    "def note_trigram_probability(midi_files):\n",
    "    trigrams = defaultdict(int)\n",
    "    for file in midi_files:\n",
    "        note_events = note_extraction(file)\n",
    "        for (note1, note2, note3) in zip(note_events[:-2], note_events[1:-1], note_events[2:]):\n",
    "            trigrams[(note1, note2, note3)] += 1\n",
    "            \n",
    "    trigramTransitions = defaultdict(list)\n",
    "    trigramTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    for t1,t2,t3 in trigrams:\n",
    "        trigramTransitions[(t1,t2)].append(t3)\n",
    "        trigramTransitionProbabilities[(t1,t2)].append(trigrams[(t1,t2,t3)])\n",
    "        \n",
    "    for k in trigramTransitionProbabilities:\n",
    "        Z = sum(trigramTransitionProbabilities[k])\n",
    "        trigramTransitionProbabilities[k] = [x / Z for x in trigramTransitionProbabilities[k]]\n",
    "        \n",
    "    return trigramTransitions, trigramTransitionProbabilities\n",
    "\n",
    "#   Computes the perplexity of the trigram model on a given MIDI file.\n",
    "#   Uses:\n",
    "#       - p(w1) from unigram\n",
    "#       - p(w2 | w1) from bigram\n",
    "#       - p(w_i | w_{i-2}, w_{i-1}) for i > 2\n",
    "#   Returns the perplexity value as a float.\n",
    "\n",
    "def note_trigram_perplexity(midi_file):\n",
    "    unigramProbabilities = note_unigram_probability(midi_files)\n",
    "    bigramTransitions, bigramTransitionProbabilities = note_bigram_probability(midi_files)\n",
    "    trigramTransitions, trigramTransitionProbabilities = note_trigram_probability(midi_files)\n",
    "    \n",
    "    note_events = note_extraction(midi_file)\n",
    "    perplexities = [unigramProbabilities[note_events[0]]]\n",
    "    index = bigramTransitions[note_events[0]].index(note_events[1])\n",
    "    prob = bigramTransitionProbabilities[note_events[0]][index]\n",
    "    perplexities.append(prob)\n",
    "    \n",
    "    for (note1, note2, note3) in zip(note_events[:-2], note_events[1:-1], note_events[2:]):\n",
    "        index = trigramTransitions[(note1, note2)].index(note3)\n",
    "        prob = trigramTransitionProbabilities[(note1, note2)][index]\n",
    "        perplexities.append(prob)\n",
    "\n",
    "    assert len(perplexities) == len(note_events)\n",
    "    perplexity = np.exp(-np.sum(np.log(perplexities)) / len(note_events))\n",
    "    return perplexity\n",
    "\n",
    "#   Extracts a list of (beat_position, beat_length) pairs from a MIDI file using REMI tokens.\n",
    "#   The beat position is taken from the 'Position_x' token, and beat length is looked up using\n",
    "#   the duration2length table based on the 'Duration_x' token.\n",
    "#   This captures rhythmic motifs and will be useful for modeling beat-level transitions or evaluating rhythm structure.\n",
    "\n",
    "duration2length = {\n",
    "    '0.2.8': 2,  # sixteenth note, 0.25 beat in 4/4 time signature\n",
    "    '0.4.8': 4,  # eighth note, 0.5 beat in 4/4 time signature\n",
    "    '1.0.8': 8,  # quarter note, 1 beat in 4/4 time signature\n",
    "    '2.0.8': 16, # half note, 2 beats in 4/4 time signature\n",
    "    '4.0.4': 32, # whole note, 4 beats in 4/4 time signature\n",
    "}\n",
    "\n",
    "#   Extracts a list of (beat_position, beat_length) pairs from a MIDI file using REMI tokens.\n",
    "#   - beat_position: extracted from the 'Position_x' token (0–31 within a bar)\n",
    "#   - beat_length: mapped from the 'Duration_x' token using the duration2length lookup table\n",
    "#   This allows analysis and modeling of beat-level rhythmic motifs.\n",
    "#   Returns:\n",
    "#       List of tuples (beat_position, beat_length)\n",
    "\n",
    "def beat_extraction(midi_file):\n",
    "    midi = Score(midi_file)\n",
    "    tokens = tokenizer(midi)[0].tokens\n",
    "    beats = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if 'Position' in tokens[i] and 'Duration' in tokens[i+3]:\n",
    "            position = int(tokens[i].split('_')[1])\n",
    "            length = duration2length[tokens[i+3].split('_')[1]]\n",
    "            beats.append((position, length))\n",
    "    return beats\n",
    "\n",
    "#   Computes bigram transition probabilities over beat lengths using extracted (beat_position, beat_length) pairs.\n",
    "#   - For each MIDI file, extract beat lengths in sequence using beat_extraction().\n",
    "#   - Count occurrences of (prev_length, next_length) transitions to build bigrams.\n",
    "#   Returns:\n",
    "#       - bigramBeatTransitions: dictionary mapping each beat length to a list of following beat lengths\n",
    "#       - bigramBeatTransitionProbabilities: corresponding list of normalized probabilities for each next beat length\n",
    "\n",
    "def beat_bigram_probability(midi_files):\n",
    "    bigramBeat = defaultdict(int)\n",
    "    for file in midi_files:\n",
    "        beats = beat_extraction(file)\n",
    "        for (beat1, beat2) in zip(beats[:-1], beats[1:]):\n",
    "            bigramBeat[(beat1[1], beat2[1])] += 1\n",
    "            \n",
    "    bigramBeatTransitions = defaultdict(list)\n",
    "    bigramBeatTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    for b1,b2 in bigramBeat:\n",
    "        bigramBeatTransitions[b1].append(b2)\n",
    "        bigramBeatTransitionProbabilities[b1].append(bigramBeat[(b1,b2)])\n",
    "        \n",
    "    for k in bigramBeatTransitionProbabilities:\n",
    "        Z = sum(bigramBeatTransitionProbabilities[k])\n",
    "        bigramBeatTransitionProbabilities[k] = [x / Z for x in bigramBeatTransitionProbabilities[k]]\n",
    "        \n",
    "    return bigramBeatTransitions, bigramBeatTransitionProbabilities\n",
    "\n",
    "#   Computes the probability distribution of beat length given beat position.\n",
    "#   Returns:\n",
    "#       - bigramBeatPosTransitions: {beat_position: [beat_length1, ...]}\n",
    "#       - bigramBeatPosTransitionProbabilities: {beat_position: [p1, ...]}\n",
    "\n",
    "def beat_pos_bigram_probability(midi_files):\n",
    "    bigramBeatPos = defaultdict(int)\n",
    "    for file in midi_files:\n",
    "        beats = beat_extraction(file)\n",
    "        for beat in beats:\n",
    "            bigramBeatPos[(beat[0], beat[1])] += 1\n",
    "            \n",
    "    bigramBeatPosTransitions = defaultdict(list)\n",
    "    bigramBeatPosTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    for b1,b2 in bigramBeatPos:\n",
    "        bigramBeatPosTransitions[b1].append(b2)\n",
    "        bigramBeatPosTransitionProbabilities[b1].append(bigramBeatPos[(b1,b2)])\n",
    "        \n",
    "    for k in bigramBeatPosTransitionProbabilities:\n",
    "        Z = sum(bigramBeatPosTransitionProbabilities[k])\n",
    "        bigramBeatPosTransitionProbabilities[k] = [x / Z for x in bigramBeatPosTransitionProbabilities[k]]\n",
    "        \n",
    "    return bigramBeatPosTransitions, bigramBeatPosTransitionProbabilities\n",
    "\n",
    "#   Computes two perplexities for beat prediction:\n",
    "#       1. Using beat_length | previous_beat_length (Q7)\n",
    "#       2. Using beat_length | beat_position (Q8)\n",
    "#   Returns:\n",
    "#       Tuple (perplexity_q7, perplexity_q8)\n",
    "\n",
    "def beat_bigram_perplexity(midi_file):\n",
    "    bigramBeatTransitions, bigramBeatTransitionProbabilities = beat_bigram_probability(midi_files)\n",
    "    bigramBeatPosTransitions, bigramBeatPosTransitionProbabilities = beat_pos_bigram_probability(midi_files)\n",
    "\n",
    "    unigramBeat = defaultdict(int)\n",
    "    for file in midi_files:\n",
    "        beats = beat_extraction(file)\n",
    "        for beat in beats:\n",
    "            unigramBeat[beat[1]] += 1\n",
    "    unigramBeatProbabilities = {}\n",
    "    counts = sum(list(unigramBeat.values()))\n",
    "    for n in unigramBeat:\n",
    "        unigramBeatProbabilities[n] = unigramBeat[n] / counts\n",
    "        \n",
    "    beat_events = beat_extraction(midi_file)\n",
    "    beats = [b[1] for b in beat_events]\n",
    "\n",
    "    # perplexity for Q7\n",
    "    perplexities = [unigramBeatProbabilities[beats[0]]]\n",
    "    for (beat1, beat2) in zip(beats[:-1], beats[1:]):\n",
    "        index = bigramBeatTransitions[beat1].index(beat2)\n",
    "        prob = bigramBeatTransitionProbabilities[beat1][index]\n",
    "        perplexities.append(prob)\n",
    "    assert len(perplexities) == len(beats)\n",
    "    perplexity_Q7 = np.exp(-np.sum(np.log(perplexities)) / len(beats))\n",
    "    \n",
    "    # perplexity for Q8\n",
    "    perplexities = []\n",
    "    for (beat_position, beat_length) in beat_events:\n",
    "        index = bigramBeatPosTransitions[beat_position].index(beat_length)\n",
    "        prob = bigramBeatPosTransitionProbabilities[beat_position][index]\n",
    "        perplexities.append(prob)\n",
    "    assert len(perplexities) == len(beat_events)\n",
    "    perplexity_Q8 = np.exp(-np.sum(np.log(perplexities)) / len(beats))\n",
    "    \n",
    "    return perplexity_Q7, perplexity_Q8\n",
    "\n",
    "#   Computes trigram transition probabilities over beat lengths, conditioned on\n",
    "#   (previous_beat_length, current_beat_position).\n",
    "#   Returns:\n",
    "#       - trigramBeatTransitions: {(prev_length, position): [curr_length1, ...]}\n",
    "#       - trigramBeatTransitionProbabilities: {(prev_length, position): [p1, ...]}\n",
    "\n",
    "def beat_trigram_probability(midi_files):\n",
    "    trigramBeat = defaultdict(int)\n",
    "    for file in midi_files:\n",
    "        beats = beat_extraction(file)\n",
    "        for (beat1, beat2) in zip(beats[:-1], beats[1:]):\n",
    "            trigramBeat[(beat1[1], beat2[0], beat2[1])] += 1\n",
    "            \n",
    "    trigramBeatTransitions = defaultdict(list)\n",
    "    trigramBeatTransitionProbabilities = defaultdict(list)\n",
    "\n",
    "    for t1,t2,t3 in trigramBeat:\n",
    "        trigramBeatTransitions[(t1,t2)].append(t3)\n",
    "        trigramBeatTransitionProbabilities[(t1,t2)].append(trigramBeat[(t1,t2,t3)])\n",
    "        \n",
    "    for k in trigramBeatTransitionProbabilities:\n",
    "        Z = sum(trigramBeatTransitionProbabilities[k])\n",
    "        trigramBeatTransitionProbabilities[k] = [x / Z for x in trigramBeatTransitionProbabilities[k]]\n",
    "        \n",
    "    return trigramBeatTransitions, trigramBeatTransitionProbabilities\n",
    "\n",
    "#   Computes the perplexity of the trigram beat model on a given MIDI file.\n",
    "#   Each prediction is based on (previous_beat_length, current_beat_position) -> current_beat_length\n",
    "\n",
    "def beat_trigram_perplexity(midi_file):\n",
    "    bigramBeatPosTransitions, bigramBeatPosTransitionProbabilities = beat_pos_bigram_probability(midi_files)\n",
    "    trigramBeatTransitions, trigramBeatTransitionProbabilities = beat_trigram_probability(midi_files)\n",
    "\n",
    "    beats = beat_extraction(midi_file)\n",
    "\n",
    "    perplexities = []\n",
    "    index = bigramBeatPosTransitions[beats[0][0]].index(beats[0][1])\n",
    "    prob = bigramBeatPosTransitionProbabilities[beats[0][0]][index]\n",
    "    perplexities.append(prob)\n",
    "\n",
    "    for (beat1, beat2) in zip(beats[:-1], beats[1:]):\n",
    "        index = trigramBeatTransitions[(beat1[1], beat2[0])].index(beat2[1])\n",
    "        prob = trigramBeatTransitionProbabilities[(beat1[1], beat2[0])][index]\n",
    "        perplexities.append(prob)\n",
    "\n",
    "    assert len(perplexities) == len(beats)\n",
    "    perplexity = np.exp(-np.sum(np.log(perplexities)) / len(beats))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Markov Modeling: Note Durations\n",
    "\n",
    "To model rhythmic structure in addition to pitch, we extract and analyze note durations from the same tokenized MIDI sequences.\n",
    "\n",
    "We implement:\n",
    "- A **duration unigram model** to estimate overall rhythmic probabilities.\n",
    "- A **duration bigram model** to capture likely transitions between rhythmic values.\n",
    "- A **duration perplexity function** to evaluate model performance on unseen MIDI files.\n",
    "\n",
    "This allows us to compare rhythmic predictability across files and evaluate the diversity of generated rhythms in later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Extracts all note durations (as strings) from a single MIDI file using REMI tokens.\n",
    "\n",
    "def duration_extraction(midi_file):\n",
    "    durations = []\n",
    "    midi = Score(midi_file)\n",
    "    tokens = tokenizer(midi)[0].tokens\n",
    "    for token in tokens:\n",
    "        if 'Duration' in token:\n",
    "            duration = token.split('_')[1]\n",
    "            durations.append(duration)\n",
    "    return durations\n",
    "\n",
    "#   Aggregates duration counts over all MIDI files and returns a dictionary \n",
    "#   mapping each duration token (as string) to its total count.\n",
    "\n",
    "def duration_frequency(midi_files):\n",
    "    duration_counts = defaultdict(int)\n",
    "    for midi_file in midi_files:\n",
    "        durations = duration_extraction(midi_file)\n",
    "        for dur in durations:\n",
    "            duration_counts[dur] += 1\n",
    "    return duration_counts\n",
    "\n",
    "#   Converts duration counts to a probability distribution.\n",
    "\n",
    "def duration_unigram_probability(midi_files):\n",
    "    duration_counts = duration_frequency(midi_files)\n",
    "    total = sum(duration_counts.values())\n",
    "    return {dur: count / total for dur, count in duration_counts.items()}\n",
    "\n",
    "#   Computes bigram transition probabilities for durations.\n",
    "#   Returns:\n",
    "#       - bigramDurations: {prev_duration: [next_duration1, ...]}\n",
    "#       - bigramDurationProbabilities: {prev_duration: [p1, ...]}\n",
    "\n",
    "def duration_bigram_probability(midi_files):\n",
    "    bigrams = defaultdict(int)\n",
    "    for midi_file in midi_files:\n",
    "        durations = duration_extraction(midi_file)\n",
    "        for d1, d2 in zip(durations[:-1], durations[1:]):\n",
    "            bigrams[(d1, d2)] += 1\n",
    "    \n",
    "    bigramDurations = defaultdict(list)\n",
    "    bigramDurationProbabilities = defaultdict(list)\n",
    "    for d1, d2 in bigrams:\n",
    "        bigramDurations[d1].append(d2)\n",
    "        bigramDurationProbabilities[d1].append(bigrams[(d1, d2)])\n",
    "    \n",
    "    for d in bigramDurationProbabilities:\n",
    "        Z = sum(bigramDurationProbabilities[d])\n",
    "        bigramDurationProbabilities[d] = [p / Z for p in bigramDurationProbabilities[d]]\n",
    "    \n",
    "    return bigramDurations, bigramDurationProbabilities\n",
    "\n",
    "#   Computes the perplexity of the duration bigram model on a MIDI file.\n",
    "\n",
    "def duration_bigram_perplexity(midi_file):\n",
    "    unigramProbs = duration_unigram_probability(midi_files)\n",
    "    bigramDurations, bigramProbs = duration_bigram_probability(midi_files)\n",
    "    durations = duration_extraction(midi_file)\n",
    "\n",
    "    perplexities = [unigramProbs[durations[0]]]\n",
    "    for d1, d2 in zip(durations[:-1], durations[1:]):\n",
    "        index = bigramDurations[d1].index(d2)\n",
    "        prob = bigramProbs[d1][index]\n",
    "        perplexities.append(prob)\n",
    "\n",
    "    assert len(perplexities) == len(durations)\n",
    "    return np.exp(-np.sum(np.log(perplexities)) / len(durations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Generation with Extended Markov Models\n",
    "\n",
    "This function generates 500-note music sequences by combining extended pitch and rhythm modeling:\n",
    "\n",
    "- **Pitch Model**: Uses a trigram Markov model over notes (`note_trigram_probability`) to capture local melodic context. This improves upon Homework 3’s pitch-only models by considering two-note histories.\n",
    "\n",
    "- **Rhythm Model**: Instead of using fixed or random durations, we extend Homework 3 by modeling note durations using a **duration bigram model** (`duration_bigram_probability`). This captures rhythmic transitions between note lengths, allowing for more realistic and musically coherent rhythm generation.\n",
    "\n",
    "- **Output**: The sampled notes and durations are converted to MIDI using MIDIUtil, with durations mapped from REMI tokens and scaled by dividing their encoded beat lengths by 8. The final composition is saved as `a2.mid`.\n",
    "\n",
    "These extensions improve musicality by introducing both melodic structure and expressive rhythmic variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_generate(length):\n",
    "    # === PITCH SAMPLING USING TRIGRAM MODEL ===\n",
    "    unigramProbs = note_unigram_probability(midi_files)\n",
    "    bigramTrans, bigramProbs = note_bigram_probability(midi_files)\n",
    "    trigramTrans, trigramProbs = note_trigram_probability(midi_files)\n",
    "\n",
    "    first_note = choice(list(unigramProbs.keys()), p=list(unigramProbs.values()))\n",
    "    second_note = choice(bigramTrans[first_note], p=bigramProbs[first_note])\n",
    "    sampled_notes = [first_note, second_note]\n",
    "\n",
    "    while len(sampled_notes) < length:\n",
    "        prev_pair = (sampled_notes[-2], sampled_notes[-1])\n",
    "        if prev_pair not in trigramTrans:\n",
    "            break\n",
    "        next_note = choice(trigramTrans[prev_pair], p=trigramProbs[prev_pair])\n",
    "        sampled_notes.append(next_note)\n",
    "\n",
    "    # === DURATION SAMPLING USING DURATION BIGRAM MODEL ===\n",
    "    dur_map = {'0.2.8': 2, '0.4.8': 4, '1.0.8': 8, '2.0.8': 16, '4.0.4': 32}\n",
    "    durationTrans, durationProbs = duration_bigram_probability(midi_files)\n",
    "\n",
    "    first_dur = choice(list(durationTrans.keys()))\n",
    "    sampled_durations = [first_dur]\n",
    "\n",
    "    while len(sampled_durations) < length:\n",
    "        prev = sampled_durations[-1]\n",
    "        if prev not in durationTrans:\n",
    "            break\n",
    "        next_dur = choice(durationTrans[prev], p=durationProbs[prev])\n",
    "        sampled_durations.append(next_dur)\n",
    "\n",
    "    # Filter + convert to beat units\n",
    "    durations = [dur_map[d] / 8 for d in sampled_durations if d in dur_map]\n",
    "    min_len = min(len(sampled_notes), len(durations))\n",
    "    sampled_notes = sampled_notes[:min_len]\n",
    "    durations = durations[:min_len]\n",
    "\n",
    "    # === WRITE TO MIDI FILE ===\n",
    "    midi = MIDIFile(1)\n",
    "    track = 0\n",
    "    tempo = 120\n",
    "    midi.addTempo(track, 0, tempo)\n",
    "\n",
    "    current_time = 0\n",
    "    note_count = 0\n",
    "    total_duration = 0\n",
    "\n",
    "    for pitch, dur in zip(sampled_notes, durations):\n",
    "        if dur <= 0:\n",
    "            continue\n",
    "        midi.addNote(track, channel=0, pitch=pitch, time=current_time, duration=dur, volume=100)\n",
    "        current_time += dur\n",
    "        note_count += 1\n",
    "        total_duration += dur\n",
    "\n",
    "    print(f\"Generated {note_count} notes, total duration: {total_duration:.2f} beats\")\n",
    "    if note_count == 0:\n",
    "        print(\"⚠️ No notes added — possibly invalid durations or pitches.\")\n",
    "    elif total_duration < 1:\n",
    "        print(\"⚠️ Total duration is too short — increase note durations or inspect duration model.\")\n",
    "\n",
    "    with open(\"a2.mid\", \"wb\") as f:\n",
    "        midi.writeFile(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Completion\n",
    "\n",
    "This section fulfills the requirements of **Assignment 2 – Task 1: Symbolic, Unconditioned Generation**.\n",
    "\n",
    "- We train a model that learns a symbolic music distribution p(x) over note sequences from a given MIDI dataset.\n",
    "- While Homework 3 introduced basic pitch-based Markov models, this implementation significantly extends that baseline by:\n",
    "  - Using a **trigram model** for pitch, enabling more coherent melodic structure.\n",
    "  - Introducing a **duration bigram model**, which learns transitions between note lengths, adding rhythmic expressiveness to the generated music.\n",
    "- These two models are sampled together to generate complete unconditioned sequences of symbolic music.\n",
    "- The final output is a self-contained MIDI file (`a2.mid`) that samples from the learned distribution p(x) without any external conditioning (e.g., no prompts or templates).\n",
    "\n",
    "Therefore, this meets the definition of symbolic, unconditioned generation using a significantly extended Markov model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 notes, total duration: 287.25 beats\n",
      "MIDI generation complete.\n",
      "File exists: True\n",
      "File size: 4545 bytes\n"
     ]
    }
   ],
   "source": [
    "# Generate 500 notes and save as MIDI, then play back\n",
    "\n",
    "music_generate(500)\n",
    "\n",
    "# Debug: Check that note and beat lengths match and are valid\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"MIDI generation complete.\")\n",
    "print(f\"File exists: {Path('a2.mid').exists()}\")\n",
    "print(f\"File size: {Path('a2.mid').stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 – Task 2: Conditional Composer-Style Melody Generation\n",
    "\n",
    "This notebook implements a conditional symbolic generation model by learning a separate pitch Markov chain for each composer using the labeled dataset from Assignment 1. For each composer with sufficient data (20+ MIDI files), we tokenize symbolic music data using MiDiTok's REMI format and build a trigram pitch model.\n",
    "\n",
    "Given a composer name (e.g., Chopin, Beethoven, Mozart), the model samples a new symbolic melody conditioned on that composer's learned pitch distribution. This allows us to stylistically generate melodies that reflect each composer’s unique musical tendencies.\n",
    "\n",
    "This satisfies Task 2 of Assignment 2 under the category of *conditional symbolic generation*, where the conditioning variable is the composer identity. The generated output is symbolic (MIDI pitch sequences) and learned from real composer-labeled data. This approach highlights the stylistic variation across composers using interpretable and modular trigram models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chopin: ['task1_composer_classification/midis/0.mid', 'task1_composer_classification/midis/2.mid']\n",
      "Beethoven: ['task1_composer_classification/midis/1.mid', 'task1_composer_classification/midis/4.mid']\n",
      "Bach: ['task1_composer_classification/midis/7.mid', 'task1_composer_classification/midis/19.mid']\n",
      "Liszt: ['task1_composer_classification/midis/8.mid', 'task1_composer_classification/midis/16.mid']\n",
      "Schumann: ['task1_composer_classification/midis/13.mid', 'task1_composer_classification/midis/71.mid']\n",
      "Schubert: ['task1_composer_classification/midis/17.mid', 'task1_composer_classification/midis/21.mid']\n",
      "Haydn: ['task1_composer_classification/midis/41.mid', 'task1_composer_classification/midis/64.mid']\n",
      "Mozart: ['task1_composer_classification/midis/113.mid', 'task1_composer_classification/midis/201.mid']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your data\n",
    "base_dir = Path(\"task1_composer_classification\")\n",
    "midi_dir = base_dir / \"midis\"\n",
    "train_json = base_dir / \"train.json\"\n",
    "\n",
    "# Load train.json using ast since it's not valid JSON\n",
    "with open(train_json, \"r\") as f:\n",
    "    train_data = ast.literal_eval(f.read())\n",
    "\n",
    "# Group MIDI files by composer\n",
    "composer_to_midis = defaultdict(list)\n",
    "for path, composer in train_data.items():\n",
    "    composer_to_midis[composer].append(str(midi_dir / Path(path).name))\n",
    "\n",
    "# Example: print 2 files per composer\n",
    "for composer, files in composer_to_midis.items():\n",
    "    print(f\"{composer}: {files[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining composers with ≥20 MIDIs:\n",
      "Chopin: 208 files\n",
      "Beethoven: 490 files\n",
      "Bach: 139 files\n",
      "Liszt: 116 files\n",
      "Schumann: 49 files\n",
      "Schubert: 120 files\n",
      "Haydn: 51 files\n",
      "Mozart: 37 files\n"
     ]
    }
   ],
   "source": [
    "# Only keep composers with at least 20 files\n",
    "composer_to_midis = {comp: files for comp, files in composer_to_midis.items() if len(files) >= 20}\n",
    "\n",
    "# Print remaining composers and file counts\n",
    "print(\"Remaining composers with ≥20 MIDIs:\")\n",
    "for composer, files in composer_to_midis.items():\n",
    "    print(f\"{composer}: {len(files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "composer_models = {}\n",
    "\n",
    "for composer, files in composer_to_midis.items():\n",
    "    trigramTrans, trigramProbs = note_trigram_probability(files)\n",
    "    composer_models[composer] = (trigramTrans, trigramProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_from_composer(composer, length=100):\n",
    "    trigramTrans, trigramProbs = composer_models[composer]\n",
    "\n",
    "    # seed notes\n",
    "    keys = list(trigramTrans.keys())\n",
    "    seed = random.choice(keys)\n",
    "    output = [seed[0], seed[1]]\n",
    "\n",
    "    while len(output) < length:\n",
    "        key = (output[-2], output[-1])\n",
    "        if key not in trigramTrans:\n",
    "            break\n",
    "        next_note = choice(trigramTrans[key], p=trigramProbs[key])\n",
    "        output.append(next_note)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_midi(pitches, output_file=\"composer_output.mid\", duration=0.5):\n",
    "    midi = MIDIFile(1)\n",
    "    midi.addTempo(0, 0, 120)\n",
    "\n",
    "    time = 0\n",
    "    for pitch in pitches:\n",
    "        midi.addNote(0, 0, pitch, time, duration, 100)\n",
    "        time += duration\n",
    "\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        midi.writeFile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for composer in [\"Chopin\", \"Beethoven\", \"Mozart\"]:\n",
    "    notes = generate_notes_from_composer(composer, length=100)\n",
    "    write_to_midi(notes, output_file=f\"{composer.lower()}_sample.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
