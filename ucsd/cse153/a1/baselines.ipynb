{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably more imports than are really necessary...\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import miditoolkit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "import random\n",
    "from music21 import converter, chord\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48503b3f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255b620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56e40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy2(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f190f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = ['rock', 'oldies', 'jazz', 'pop', 'dance',  'blues',  'punk', 'chill', 'electronic', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b772218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy3(groundtruth, predictions):\n",
    "    preds, targets = [], []\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        prediction = [1 if tag in predictions[k] else 0 for tag in TAGS]\n",
    "        target = [1 if tag in groundtruth[k] else 0 for tag in TAGS]\n",
    "        preds.append(prediction)\n",
    "        targets.append(target)\n",
    "    \n",
    "    mAP = average_precision_score(targets, preds, average='macro')\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487755c",
   "metadata": {},
   "source": [
    "## Task 1: Composer classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fdbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot1 = \"student_files/task1_composer_classification/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b686224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=100)\n",
    "\n",
    "    def get_all_notes(self, midi_obj):\n",
    "        notes = []\n",
    "        for inst in midi_obj.instruments:\n",
    "            notes.extend(inst.notes)\n",
    "        return sorted(notes, key=lambda n: n.start)\n",
    "\n",
    "    def get_chord_sequence(self, path):\n",
    "\n",
    "        try:\n",
    "            score = converter.parse(dataroot1 + '/' + path)\n",
    "            chords = score.chordify().recurse().getElementsByClass('Chord')\n",
    "            roman_progression = [chord.Chord(c.pitches).pitchedCommonName for c in chords]\n",
    "            return ' '.join(roman_progression)\n",
    "        \n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "    def get_pitch_features(self, notes):\n",
    "        if not notes:\n",
    "            return [0] * (6 + 12 + 12 + 144)\n",
    "\n",
    "        total_time = notes[-1].end\n",
    "        stats = [\n",
    "            min(note.pitch for note in notes),\n",
    "            max(note.pitch for note in notes),\n",
    "            len(set(note.pitch for note in notes)),\n",
    "            sum(note.pitch for note in notes) / len(notes),\n",
    "            sum(note.end - note.start for note in notes) / len(notes),\n",
    "            len(notes) / total_time if total_time > 0 else 0,\n",
    "        ]\n",
    "        pitch_hist = [0] * 12\n",
    "\n",
    "        for note in notes:\n",
    "            pitch_hist[note.pitch % 12] += 1\n",
    "\n",
    "        total = sum(pitch_hist)\n",
    "        pitch_hist = [x / total for x in pitch_hist] if total > 0 else pitch_hist\n",
    "        interval_hist = [0] * 12\n",
    "\n",
    "        if len(notes) >= 2:\n",
    "            intervals = [abs(notes[i].pitch - notes[i-1].pitch) % 12 for i in range(1, len(notes))]\n",
    "\n",
    "            for i in intervals:\n",
    "                interval_hist[i] += 1\n",
    "\n",
    "            total = sum(interval_hist)\n",
    "            interval_hist = [x / total for x in interval_hist] if total > 0 else interval_hist\n",
    "\n",
    "        bigram_hist = [0] * 144\n",
    "\n",
    "        if len(notes) >= 3:\n",
    "\n",
    "            bigrams = [(abs(notes[i].pitch - notes[i-1].pitch) % 12, abs(notes[i+1].pitch - notes[i].pitch) % 12) for i in range(len(notes) - 2)]\n",
    "\n",
    "            for i1, i2 in bigrams:\n",
    "                bigram_hist[i1 * 12 + i2] += 1\n",
    "\n",
    "            total = sum(bigram_hist)\n",
    "            bigram_hist = [x / total for x in bigram_hist] if total > 0 else bigram_hist\n",
    "\n",
    "        return stats + pitch_hist + interval_hist + bigram_hist\n",
    "\n",
    "    def get_meta(self, midi_obj, path):\n",
    "\n",
    "        try:\n",
    "            score = converter.parse(dataroot1 + '/' + path)\n",
    "            key = score.analyze('key')\n",
    "            tonic_class = key.tonic.pitchClass\n",
    "            mode_val = 1 if key.mode == 'major' else 0\n",
    "\n",
    "        except:\n",
    "            tonic_class, mode_val = 0, 0\n",
    "\n",
    "        if midi_obj.tempo_changes:\n",
    "            tempo_micro = midi_obj.tempo_changes[0].tempo\n",
    "            bpm = 60000000 / tempo_micro\n",
    "\n",
    "        else:\n",
    "            bpm = 120\n",
    "\n",
    "        return [bpm, tonic_class, mode_val]\n",
    "\n",
    "    def features(self, path, include_tfidf=False):\n",
    "\n",
    "        midi_obj = miditoolkit.midi.parser.MidiFile(dataroot1 + '/' + path)\n",
    "        notes = self.get_all_notes(midi_obj)\n",
    "        chord_seq = self.get_chord_sequence(path)\n",
    "        base_feats = self.get_pitch_features(notes) + self.get_meta(midi_obj, path)\n",
    "        return (base_feats, chord_seq) if include_tfidf else base_feats\n",
    "\n",
    "    def train(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            train_json = eval(f.read())\n",
    "\n",
    "        paths = list(train_json.keys())\n",
    "        labels = list(train_json.values())\n",
    "\n",
    "        base_X = []\n",
    "        chord_texts = []\n",
    "\n",
    "        for p in tqdm(paths, desc=\"Extracting features\"):\n",
    "            bf, chord_str = self.features(p, include_tfidf=True)\n",
    "            base_X.append(bf)\n",
    "            chord_texts.append(chord_str)\n",
    "\n",
    "        tfidf_X = self.vectorizer.fit_transform(chord_texts).toarray()\n",
    "        X = [np.concatenate([b, t]) for b, t in zip(base_X, tfidf_X)]\n",
    "        y = labels\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        self.model = HistGradientBoostingClassifier(\n",
    "            max_iter=300,\n",
    "            learning_rate=0.05,\n",
    "            max_leaf_nodes=64,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X_train, y_train)\n",
    "        val_preds = self.model.predict(X_val)\n",
    "        print(\"Validation accuracy =\", accuracy_score(y_val, val_preds))\n",
    "\n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "\n",
    "        for k in tqdm(d, desc=\"Predicting\"):\n",
    "            base_feats, chord_str = self.features(k, include_tfidf=True)\n",
    "            tfidf_feats = self.vectorizer.transform([chord_str]).toarray()[0]\n",
    "            x = np.concatenate([base_feats, tfidf_feats])\n",
    "            pred = self.model.predict([x])\n",
    "            predictions[k] = str(pred[0])\n",
    "\n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83a314",
   "metadata": {},
   "source": [
    "## Task 2: Sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9aaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot2 = \"student_files/task2_next_sequence_prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac072a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model2():\n",
    "    def __init__(self, threshold=0.48):  # Allow tuning threshold\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def extract_features(self, path):\n",
    "        midi_path = dataroot2 + '/' + path\n",
    "        midi_obj = miditoolkit.midi.parser.MidiFile(midi_path)\n",
    "\n",
    "        # Return all zeros if MIDI is empty or broken\n",
    "        if len(midi_obj.instruments) == 0 or len(midi_obj.instruments[0].notes) == 0:\n",
    "            return [0] * (6 + 12 + 3 + 2)\n",
    "\n",
    "        notes = sorted(midi_obj.instruments[0].notes, key=lambda n: n.start)\n",
    "        total_time = midi_obj.max_tick / midi_obj.ticks_per_beat  # in beats\n",
    "\n",
    "        # Base features\n",
    "        features = [\n",
    "            min(note.pitch for note in notes),\n",
    "            max(note.pitch for note in notes),\n",
    "            len(set(note.pitch for note in notes)),\n",
    "            sum(note.pitch for note in notes) / len(notes),\n",
    "            sum(note.end - note.start for note in notes) / len(notes),\n",
    "            len(notes) / total_time if total_time > 0 else 0\n",
    "        ]\n",
    "\n",
    "        # Interval histogram\n",
    "        intervals = [abs(notes[i].pitch - notes[i - 1].pitch) % 12 for i in range(1, len(notes))]\n",
    "        interval_hist = [0] * 12\n",
    "        for i in intervals:\n",
    "            interval_hist[i] += 1\n",
    "        total_int = sum(interval_hist)\n",
    "        interval_hist = [x / total_int for x in interval_hist] if total_int > 0 else interval_hist\n",
    "\n",
    "        # Rhythm features\n",
    "        durations = [note.end - note.start for note in notes]\n",
    "        rhythm_features = [\n",
    "            np.mean(durations),\n",
    "            np.std(durations),\n",
    "            max(durations) / np.mean(durations) if np.mean(durations) > 0 else 0\n",
    "        ]\n",
    "\n",
    "        # Key signature features\n",
    "        try:\n",
    "            score = converter.parse(midi_path)\n",
    "            key = score.analyze('key')\n",
    "            key_features = [key.tonic.pitchClass, 1 if key.mode == 'major' else 0]\n",
    "        except:\n",
    "            key_features = [0, 0]\n",
    "\n",
    "        return features + interval_hist + rhythm_features + key_features\n",
    "\n",
    "    def combine_pair_features(self, f1, f2):\n",
    "        f1 = np.array(f1)\n",
    "        f2 = np.array(f2)\n",
    "        return np.concatenate([\n",
    "            f1,\n",
    "            f2,\n",
    "            np.abs(f1 - f2),\n",
    "            f1 * f2,\n",
    "            np.minimum(f1, f2),\n",
    "            np.maximum(f1, f2),\n",
    "            f1 / (f2 + 1e-6),\n",
    "            f2 / (f1 + 1e-6)\n",
    "        ]).tolist()\n",
    "\n",
    "    def train(self, path):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        X, y = [], []\n",
    "\n",
    "        for (p1, p2), label in tqdm(d.items(), desc=\"Extracting train features\"):\n",
    "            f1 = self.extract_features(p1)\n",
    "            f2 = self.extract_features(p2)\n",
    "            combined = self.combine_pair_features(f1, f2)\n",
    "            X.append(combined)\n",
    "            y.append(label)\n",
    "\n",
    "        self.model = lgb.LGBMClassifier(\n",
    "            n_estimators=400,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=128,\n",
    "            max_depth=10,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            colsample_bytree=0.9,\n",
    "            subsample=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "\n",
    "        for (p1, p2) in tqdm(d, desc=\"Predicting\"):\n",
    "            f1 = self.extract_features(p1)\n",
    "            f2 = self.extract_features(p2)\n",
    "            combined = self.combine_pair_features(f1, f2)\n",
    "            prob = self.model.predict_proba([combined])[0][1]\n",
    "            predictions[(p1, p2)] = prob > self.threshold\n",
    "\n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36bf2cf",
   "metadata": {},
   "source": [
    "## Task 3: Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants (you can change any of these if useful)\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "N_CLASSES = 10\n",
    "AUDIO_DURATION = 10 # seconds\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# %%\n",
    "dataroot3 = \"student_files/task3_audio_classification/\"\n",
    "\n",
    "def extract_waveform(path):\n",
    "    waveform, sr = librosa.load(dataroot3 + '/' + path, sr=SAMPLE_RATE)\n",
    "    waveform = np.array([waveform])\n",
    "    if sr != SAMPLE_RATE:\n",
    "        resample = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "        waveform = resample(waveform)\n",
    "    # Pad so that everything is the right length\n",
    "    target_len = SAMPLE_RATE * AUDIO_DURATION\n",
    "    if waveform.shape[1] < target_len:\n",
    "        pad_len = target_len - waveform.shape[1]\n",
    "        waveform = F.pad(waveform, (0, pad_len))\n",
    "    else:\n",
    "        waveform = waveform[:, :target_len]\n",
    "    waveform = torch.FloatTensor(waveform)\n",
    "    return waveform\n",
    "\n",
    "# %%\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, meta, preload = True):\n",
    "        self.meta = meta\n",
    "        ks = list(meta.keys())\n",
    "        self.idToPath = dict(zip(range(len(ks)), ks))\n",
    "        self.pathToFeat = {}\n",
    "\n",
    "        self.mel = MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=N_MELS)\n",
    "        self.db = AmplitudeToDB()\n",
    "        \n",
    "        self.preload = preload # Determines whether the features should be preloaded (uses more memory)\n",
    "                               # or read from disk / computed each time (slow if your system is i/o-bound)\n",
    "        if self.preload:\n",
    "            for path in ks:\n",
    "                waveform = extract_waveform(path)\n",
    "                mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "                self.pathToFeat[path] = mel_spec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Faster version, preloads the features\n",
    "        path = self.idToPath[idx]\n",
    "        tags = self.meta[path]\n",
    "        bin_label = torch.tensor([1 if tag in tags else 0 for tag in TAGS], dtype=torch.float32)\n",
    "\n",
    "        if self.preload:\n",
    "            mel_spec = self.pathToFeat[path]\n",
    "        else:\n",
    "            waveform = extract_waveform(path)\n",
    "            mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "        \n",
    "        return mel_spec.unsqueeze(0), bin_label, path\n",
    "\n",
    "# %%\n",
    "class Loaders():\n",
    "    def __init__(self, train_path, test_path, split_ratio=0.9, seed = 0):\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        meta_train = eval(open(train_path, 'r').read())\n",
    "        l_test = eval(open(test_path, 'r').read())\n",
    "        meta_test = dict([(x,[]) for x in l_test]) # Need a dictionary for the above class\n",
    "        \n",
    "        all_train = AudioDataset(meta_train)\n",
    "        test_set = AudioDataset(meta_test)\n",
    "        \n",
    "        # Split all_train into train + valid\n",
    "        total_len = len(all_train)\n",
    "        train_len = int(total_len * split_ratio)\n",
    "        valid_len = total_len - train_len\n",
    "        train_set, valid_set = random_split(all_train, [train_len, valid_len])\n",
    "        \n",
    "        self.loaderTrain = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "        self.loaderValid = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "        self.loaderTest = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# %%\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=N_CLASSES):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc1 = nn.Linear(32 * (N_MELS // 4) * (801 // 4), 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 16, mel/2, time/2)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, mel/4, time/4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return torch.sigmoid(self.fc2(x))  # multilabel → sigmoid\n",
    "\n",
    "# %%\n",
    "class Pipeline():\n",
    "    def __init__(self, model, learning_rate, seed = 0):\n",
    "        # These two lines will (mostly) make things deterministic.\n",
    "        # You're welcome to modify them to try to get a better solution.\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        self.device = torch.device(\"cpu\") # Can change this if you have a GPU, but the autograder will use CPU\n",
    "        self.model = model.to(self.device) #model.cuda() # Also uncomment these lines for GPU\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def evaluate(self, loader, threshold=0.5, outpath=None):\n",
    "        self.model.eval()\n",
    "        preds, targets, paths = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y, ps in loader:\n",
    "                x = x.to(self.device) #x.cuda()\n",
    "                y = y.to(self.device) #y.cuda()\n",
    "                outputs = self.model(x)\n",
    "                preds.append(outputs.cpu())\n",
    "                targets.append(y.cpu())\n",
    "                paths += list(ps)\n",
    "        \n",
    "        preds = torch.cat(preds)\n",
    "        targets = torch.cat(targets)\n",
    "        preds_bin = (preds > threshold).float()\n",
    "        \n",
    "        predictions = {}\n",
    "        for i in range(preds_bin.shape[0]):\n",
    "            predictions[paths[i]] = [TAGS[j] for j in range(len(preds_bin[i])) if preds_bin[i][j]]\n",
    "        \n",
    "        mAP = None\n",
    "        if outpath: # Save predictions\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        else: # Only compute accuracy if we're *not* saving predictions, since we can't compute test accuracy\n",
    "            mAP = average_precision_score(targets, preds, average='macro')\n",
    "        return predictions, mAP\n",
    "\n",
    "    def train(self, train_loader, val_loader, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for x, y, path in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "                x = x.to(self.device) #x.cuda()\n",
    "                y = y.to(self.device) #y.cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x)\n",
    "                loss = self.criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            val_predictions, mAP = self.evaluate(val_loader)\n",
    "            print(f\"[Epoch {epoch+1}] Loss: {running_loss/len(train_loader):.4f} | Val mAP: {mAP:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87197d0",
   "metadata": {},
   "source": [
    "## Run everything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9708d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run1():\n",
    "    model = model1()\n",
    "    model.train(dataroot1 + \"/train.json\")\n",
    "    train_preds = model.predict(dataroot1 + \"/train.json\")\n",
    "    test_preds = model.predict(dataroot1 + \"/test.json\", \"predictions1.json\")\n",
    "    \n",
    "    train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
    "    acc1 = accuracy1(train_labels, train_preds)\n",
    "    print(\"Task 1 training accuracy = \" + str(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb50b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2():\n",
    "    model = model2()\n",
    "    model.train(dataroot2 + \"/train.json\")\n",
    "    train_preds = model.predict(dataroot2 + \"/train.json\")\n",
    "    test_preds = model.predict(dataroot2 + \"/test.json\", \"predictions2.json\")\n",
    "    \n",
    "    train_labels = eval(open(dataroot2 + \"/train.json\").read())\n",
    "    acc2 = accuracy2(train_labels, train_preds)\n",
    "    print(\"Task 2 training accuracy = \" + str(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run3():\n",
    "    loaders = Loaders(dataroot3 + \"/train.json\", dataroot3 + \"/test.json\")\n",
    "    model = CNNClassifier()\n",
    "    pipeline = Pipeline(model, 3e-4)\n",
    "    \n",
    "    pipeline.train(loaders.loaderTrain, loaders.loaderValid, 15)\n",
    "    train_preds, train_mAP = pipeline.evaluate(loaders.loaderTrain, 0.5)\n",
    "    valid_preds, valid_mAP = pipeline.evaluate(loaders.loaderValid, 0.5)\n",
    "    test_preds, _ = pipeline.evaluate(loaders.loaderTest, 0.5, \"predictions3.json\")\n",
    "    \n",
    "    all_train = eval(open(dataroot3 + \"/train.json\").read())\n",
    "    for k in valid_preds:\n",
    "        # We split our training set into train+valid\n",
    "        # so need to remove validation instances from the training set for evaluation\n",
    "        all_train.pop(k)\n",
    "    acc3 = accuracy3(all_train, train_preds)\n",
    "    print(\"Task 3 training mAP = \" + str(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "458d6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 training accuracy = 0.41074380165289254\n"
     ]
    }
   ],
   "source": [
    "run1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0286c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 training accuracy = 0.5981376857083072\n"
     ]
    }
   ],
   "source": [
    "run2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f2c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 113/113 [00:45<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "run3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8b523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
