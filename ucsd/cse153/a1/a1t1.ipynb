{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7005d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably more imports than are really necessary...\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import miditoolkit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "import random\n",
    "from music21 import converter, chord\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48503b3f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255b620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56e40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy2(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f190f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = ['rock', 'oldies', 'jazz', 'pop', 'dance',  'blues',  'punk', 'chill', 'electronic', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b772218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy3(groundtruth, predictions):\n",
    "    preds, targets = [], []\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        prediction = [1 if tag in predictions[k] else 0 for tag in TAGS]\n",
    "        target = [1 if tag in groundtruth[k] else 0 for tag in TAGS]\n",
    "        preds.append(prediction)\n",
    "        targets.append(target)\n",
    "    \n",
    "    mAP = average_precision_score(targets, preds, average='macro')\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487755c",
   "metadata": {},
   "source": [
    "## Task 1: Composer classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fdbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot1 = \"student_files/task1_composer_classification/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b686224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=100)\n",
    "\n",
    "    def get_all_notes(self, midi_obj):\n",
    "        notes = []\n",
    "        for inst in midi_obj.instruments:\n",
    "            notes.extend(inst.notes)\n",
    "        return sorted(notes, key=lambda n: n.start)\n",
    "\n",
    "    def get_chord_sequence(self, path):\n",
    "\n",
    "        try:\n",
    "            score = converter.parse(dataroot1 + '/' + path)\n",
    "            chords = score.chordify().recurse().getElementsByClass('Chord')\n",
    "            roman_progression = [chord.Chord(c.pitches).pitchedCommonName for c in chords]\n",
    "            return ' '.join(roman_progression)\n",
    "        \n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "    def get_pitch_features(self, notes):\n",
    "        if not notes:\n",
    "            return [0] * (6 + 12 + 12 + 144)\n",
    "\n",
    "        total_time = notes[-1].end\n",
    "        stats = [\n",
    "            min(note.pitch for note in notes),\n",
    "            max(note.pitch for note in notes),\n",
    "            len(set(note.pitch for note in notes)),\n",
    "            sum(note.pitch for note in notes) / len(notes),\n",
    "            sum(note.end - note.start for note in notes) / len(notes),\n",
    "            len(notes) / total_time if total_time > 0 else 0,\n",
    "        ]\n",
    "        pitch_hist = [0] * 12\n",
    "\n",
    "        for note in notes:\n",
    "            pitch_hist[note.pitch % 12] += 1\n",
    "\n",
    "        total = sum(pitch_hist)\n",
    "        pitch_hist = [x / total for x in pitch_hist] if total > 0 else pitch_hist\n",
    "        interval_hist = [0] * 12\n",
    "\n",
    "        if len(notes) >= 2:\n",
    "            intervals = [abs(notes[i].pitch - notes[i-1].pitch) % 12 for i in range(1, len(notes))]\n",
    "\n",
    "            for i in intervals:\n",
    "                interval_hist[i] += 1\n",
    "\n",
    "            total = sum(interval_hist)\n",
    "            interval_hist = [x / total for x in interval_hist] if total > 0 else interval_hist\n",
    "\n",
    "        bigram_hist = [0] * 144\n",
    "\n",
    "        if len(notes) >= 3:\n",
    "\n",
    "            bigrams = [(abs(notes[i].pitch - notes[i-1].pitch) % 12, abs(notes[i+1].pitch - notes[i].pitch) % 12) for i in range(len(notes) - 2)]\n",
    "\n",
    "            for i1, i2 in bigrams:\n",
    "                bigram_hist[i1 * 12 + i2] += 1\n",
    "\n",
    "            total = sum(bigram_hist)\n",
    "            bigram_hist = [x / total for x in bigram_hist] if total > 0 else bigram_hist\n",
    "\n",
    "        return stats + pitch_hist + interval_hist + bigram_hist\n",
    "\n",
    "    def get_meta(self, midi_obj, path):\n",
    "\n",
    "        try:\n",
    "            score = converter.parse(dataroot1 + '/' + path)\n",
    "            key = score.analyze('key')\n",
    "            tonic_class = key.tonic.pitchClass\n",
    "            mode_val = 1 if key.mode == 'major' else 0\n",
    "\n",
    "        except:\n",
    "            tonic_class, mode_val = 0, 0\n",
    "\n",
    "        if midi_obj.tempo_changes:\n",
    "            tempo_micro = midi_obj.tempo_changes[0].tempo\n",
    "            bpm = 60000000 / tempo_micro\n",
    "\n",
    "        else:\n",
    "            bpm = 120\n",
    "\n",
    "        return [bpm, tonic_class, mode_val]\n",
    "\n",
    "    def features(self, path, include_tfidf=False):\n",
    "\n",
    "        midi_obj = miditoolkit.midi.parser.MidiFile(dataroot1 + '/' + path)\n",
    "        notes = self.get_all_notes(midi_obj)\n",
    "        chord_seq = self.get_chord_sequence(path)\n",
    "        base_feats = self.get_pitch_features(notes) + self.get_meta(midi_obj, path)\n",
    "        return (base_feats, chord_seq) if include_tfidf else base_feats\n",
    "\n",
    "    def train(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            train_json = eval(f.read())\n",
    "\n",
    "        paths = list(train_json.keys())\n",
    "        labels = list(train_json.values())\n",
    "\n",
    "        base_X = []\n",
    "        chord_texts = []\n",
    "\n",
    "        for p in tqdm(paths, desc=\"Extracting features\"):\n",
    "            bf, chord_str = self.features(p, include_tfidf=True)\n",
    "            base_X.append(bf)\n",
    "            chord_texts.append(chord_str)\n",
    "\n",
    "        tfidf_X = self.vectorizer.fit_transform(chord_texts).toarray()\n",
    "        X = [np.concatenate([b, t]) for b, t in zip(base_X, tfidf_X)]\n",
    "        y = labels\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        self.model = HistGradientBoostingClassifier(\n",
    "            max_iter=300,\n",
    "            learning_rate=0.05,\n",
    "            max_leaf_nodes=64,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X_train, y_train)\n",
    "        val_preds = self.model.predict(X_val)\n",
    "        print(\"Validation accuracy =\", accuracy_score(y_val, val_preds))\n",
    "\n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "\n",
    "        for k in tqdm(d, desc=\"Predicting\"):\n",
    "            base_feats, chord_str = self.features(k, include_tfidf=True)\n",
    "            tfidf_feats = self.vectorizer.transform([chord_str]).toarray()[0]\n",
    "            x = np.concatenate([base_feats, tfidf_feats])\n",
    "            pred = self.model.predict([x])\n",
    "            predictions[k] = str(pred[0])\n",
    "\n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87197d0",
   "metadata": {},
   "source": [
    "## Run everything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9708d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run1():\n",
    "    model = model1()\n",
    "    model.train(dataroot1 + \"/train.json\")\n",
    "    train_preds = model.predict(dataroot1 + \"/train.json\")\n",
    "    test_preds = model.predict(dataroot1 + \"/test.json\", \"predictions1.json\")\n",
    "    \n",
    "    train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
    "    acc1 = accuracy1(train_labels, train_preds)\n",
    "    print(\"Task 1 training accuracy = \" + str(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458d6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/1210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 1210/1210 [04:01<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.8181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1210/1210 [15:02<00:00,  1.34it/s]  \n",
      "Predicting: 100%|██████████| 389/389 [02:54<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 training accuracy = 0.9636363636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
